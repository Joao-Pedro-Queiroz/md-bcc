{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b48e863-8e93-45c0-938d-c9a4566b69b8",
   "metadata": {},
   "source": [
    "# Projeto Spark\n",
    "\n",
    "Entrega: 16 de novembro de 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4813f033-927b-46ca-8977-30e8b0de48c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introdu√ß√£o\n",
    "\n",
    "Neste projeto vamos construir um classificador Naive-Bayes para determinar o sentimento de um coment√°rio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73210022",
   "metadata": {},
   "source": [
    "## Grupos\n",
    "\n",
    "O projeto pode ser individual ou em duplas. Criem os grupos em https://classroom.github.com/a/YQj6i16S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7c97a3",
   "metadata": {},
   "source": [
    "## Instalando o ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fb2a89",
   "metadata": {},
   "source": [
    "O jeito mais simples de come√ßar a trabalhar com Spark √© instalar um container com tudo pronto! No site https://hub.docker.com/r/jupyter/pyspark-notebook vemos uma imagem Docker que j√° vem com `pyspark` e `jupyter lab`. Instale a imagem com o comando:\n",
    "\n",
    "```bash\n",
    "docker pull jupyter/pyspark-notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d77aef5",
   "metadata": {},
   "source": [
    "\n",
    "Vamos iniciar o ambiente de trabalho com o comando `docker run`. Para isso precisamos tomar alguns cuidados:\n",
    "\n",
    "1) Temos que mapear nosso diretorio local de trabalho para um diret√≥rio interno do container, de modo que altera√ß√µes feitas dentro do container (nesta pasta escolhida) sejam gravadas no nosso diretorio local. No container temos um usu√°rio padr√£o com *username* `jovyan`. No *homedir* desse usuario temos uma pasta vazia `work`, que vai servir como local de mapeamento do nosso diretorio local de trabalho. Podemos ent√£o fazer esse mapeamendo com a op√ß√£o `-v` do comando `docker run` da seguinte forma:\n",
    "\n",
    "```bash\n",
    "-v <diretorio>:/home/jovyan/work\n",
    "```\n",
    "\n",
    "onde `<diretorio>` representa seu diretorio local de trabalho.\n",
    "\n",
    "2) Para acessar o `jupyter notebook` e o *dashboard* do Spark a partir do nosso *browser* favorito temos que abrir algumas portas do container com a op√ß√£o `-p`. As portas s√£o `8888` (para o pr√≥prio `jupyter notebook`) e `4040` (para o *dashboard* do Spark). Ou seja, adicionaremos √†s op√ß√µes do `docker run`o seguinte:\n",
    "\n",
    "```bash\n",
    "-p 8888:8888 -p 4040:4040\n",
    "```\n",
    "\n",
    "Desta forma, ao acessar `localhost:8888` na nossa m√°quina, estaremos acessando o servidor Jupyter na porta 8888 interna do container.\n",
    "\n",
    "3) Vamos iniciar o container no modo interativo, e vamos especificar que o container deve ser encerrado ao fechar o servidor Jupyter. Faremos isso com as op√ß√µes `-it` e `-rm`\n",
    "\n",
    "Antes de executar, garanta que as portas 4040 e 8888 est√£o livres (sem jupyter j√° executando) ou altere o comando. Ainda, esteja na pasta da aula ao executar, assim apenas ela ser√° exposta ao container.\n",
    "\n",
    "Portanto, o comando completo que eu uso na minha m√°quina Linux para iniciar o container √©:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5270810",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker run \\\n",
    "    -it \\\n",
    "    --rm \\\n",
    "    -p 8888:8888 \\\n",
    "    -p 4040:4040 \\\n",
    "    -v \"`pwd`\":/home/jovyan/work \\\n",
    "    jupyter/pyspark-notebook\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33432fba",
   "metadata": {},
   "source": [
    "Se estiver no Windows estes comandos, utilize:\n",
    "\n",
    "- No Powershell: `docker run -it --rm -p 8888:8888 -p 4040:4040 -v ${PWD}:/home/jovyan/work jupyter/pyspark-notebook`\n",
    "\n",
    "- No Prompt de comando: `docker run -it --rm -p 8888:8888 -p 4040:4040 -v %cd%:/home/jovyan/work jupyter/pyspark-notebook`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3090720d-0dec-48ff-a8da-921b62764c43",
   "metadata": {},
   "source": [
    "## Iniciando o Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603fa191-ca53-4035-9147-86f3cf27831a",
   "metadata": {},
   "source": [
    "Vamos iniciar o ambiente Spark. Para isso vamos:\n",
    "\n",
    "1) Criar um objeto de configura√ß√£o do ambiente Spark. Nossa configura√ß√£o ser√° simples: vamos especificar que o nome da nossa aplica√ß√£o Spark √© \"Minha aplica√ß√£o\", e que o *master node* √© a m√°quina local, usando todos os *cores* dispon√≠veis. Aplica√ß√µes reais de Spark s√£o configuradas de modo ligeiramente diferente: ao especificar o *master node* passamos uma URL real, com o endere√ßo do n√≥ gerente do *cluster* Spark.\n",
    "\n",
    "2) Vamos criar um objeto do tipo `SparkContext` com essa configura√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d1b7f8-ddc9-43b0-adbd-2b6e5aad182c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "conf = pyspark.SparkConf()\n",
    "conf.setAppName(\"Meu projeto Spark\")\n",
    "conf.setMaster(\"local[*]\")\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfcd1c3-3c9b-47c6-bf36-06c60b796991",
   "metadata": {},
   "source": [
    "O `SparkContext` √© a nossa porta de entrada para o cluster Spark, ele ser√° a raiz de todas as nossas opera√ß√µes com o Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5214f8ff-9df1-4817-9e08-c1755470f3b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://b2c10cc0900a:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Minha aplica√ß√£o</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=Minha aplica√ß√£o>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60acb677-070b-4191-bbad-ee16000ff380",
   "metadata": {},
   "source": [
    "O link acima provavelmente n√£o funcionar√° porque ele se refere √† porta 4040 interna do container (portanto a URL est√° com endere√ßo interno). Por√©m fizemos o mapeamento da porta 4040 interna para a porta 4040 externa, logo voc√™ pode acessar o *dashboard* do Spark no endere√ßo http://localhost:4040\n",
    "\n",
    "<center><img src=\"./spark_dashboard.png\" width=800/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44bd07e-7f64-4c0d-b522-faf5313b53cc",
   "metadata": {},
   "source": [
    "## Lendo os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c2f3af",
   "metadata": {},
   "source": [
    "Utilize os dados (`train.csv`) da aula 22. Caso queira fazer download novamente, utilize um dos links:\n",
    "\n",
    "- https://www.kaggle.com/datasets/kritanjalijain/amazon-reviews.\n",
    "- https://bigdata-22-2.s3.us-east-2.amazonaws.com/amazon_sentiment/train.csv.gz\n",
    "\n",
    "Vamos come√ßar lendo o arquivo de reviews e gravando o resultado em formato pickle, mais amig√°vel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7fda56-bf06-4309-a265-26e553e20b94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_line(line):\n",
    "    parts = line[1:-1].split('\",\"')\n",
    "    sentiment = int(parts[0])\n",
    "    title = parts[1].replace('\"\"', '\"')\n",
    "    body = parts[2].replace('\"\"', '\"')\n",
    "    return (sentiment, title, body)\n",
    "\n",
    "rdd = sc.textFile(\"train.csv\").map(parse_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "900ea746-984c-405b-a449-d6cf8885525e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e83f38e5-3d7b-4261-8ab3-caadb39d6076",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2,\n",
       "  'Stuning even for the non-gamer',\n",
       "  'This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c7933-ad3f-4a17-bf89-8e1360ddc4ab",
   "metadata": {},
   "source": [
    "Agora vamos gravar no formato pickle, para facilitar os trabalhos futuros. Ap√≥s gravar o arquivo, n√£o mais rode as c√©lulas desta primeira etapa!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39938d62-bc17-4243-a9e8-3fed9c8d2bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.saveAsPickleFile(\"reviews.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f5b5b-f0ac-4385-866b-8d8d8ecbdf9f",
   "metadata": {},
   "source": [
    "## Um classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ef2e6-ac48-46ad-b538-920c17aff6dc",
   "metadata": {},
   "source": [
    "Vamos ler o arquivo pickle gravado anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9107ce80-0447-41d7-8f83-d96f0680d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.pickleFile('reviews.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae84b476-b262-496f-93b0-19386fa9f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607f7afa-43e7-4b82-bffc-7c1cca0536ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9751aa-df6d-4e3e-a8c5-039133cefe28",
   "metadata": {},
   "source": [
    "Agora, complete as tarefas em sequencia para construir o classificador Naive-Bayes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bac409-7181-49c4-b555-73d3e9ff71f2",
   "metadata": {},
   "source": [
    "### Fase 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef78654e-d064-41b4-9be8-306a57c425f4",
   "metadata": {},
   "source": [
    "#### Tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d82f8-520e-49de-8397-5277d5bd072e",
   "metadata": {},
   "source": [
    "Construa uma fun√ß√£o que recebe um RDD no formato do RDD original e retorna um RDD no qual cada item √© um par (palavra, contagem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb48e97-e57d-4b6a-9b27-b52cd9c3d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def words_count(rdd):\n",
    "    \"\"\"\n",
    "    Recebe um RDD no formato (sentiment, title, body)\n",
    "    Retorna um RDD (palavra, contagem)\n",
    "    \"\"\"\n",
    "    \n",
    "    def tokenize(text):\n",
    "        # transforma em min√∫sculas e remove caracteres n√£o alfab√©ticos\n",
    "        return re.findall(r\"[a-zA-Z]+\", text.lower())\n",
    "    \n",
    "    return (rdd\n",
    "        # extrair apenas o texto: t√≠tulo + corpo\n",
    "        .flatMap(lambda x: tokenize(x[1] + \" \" + x[2]))\n",
    "        # criar pares (palavra, 1)\n",
    "        .map(lambda word: (word, 1))\n",
    "        # somar as ocorr√™ncias\n",
    "        .reduceByKey(lambda a, b: a + b)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d888c4-bef5-4d1c-a901-e8dc5029f1b0",
   "metadata": {},
   "source": [
    "#### Tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ec5621-6c06-4dce-b351-e887d6aa8be4",
   "metadata": {},
   "source": [
    "Construa uma fun√ß√£o que recebe o RDD (palavra, contagem) construido anteriormente e retorna um RDD no qual cada item √© um par (palavra, $\\log_{10}\\left(c \\, / \\, T\\right)$), onde $c$ √© a contagem daquela palavra e $T$ √© a soma das contagens de palavra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca379b49-a447-4ecf-9946-6c408e2adc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def to_log_prob(word_count_rdd):\n",
    "    \"\"\"\n",
    "    Recebe um RDD (palavra, contagem)\n",
    "    Retorna um RDD (palavra, log10(c/T))\n",
    "    onde T √© a soma das contagens de todas as palavras.\n",
    "    \"\"\"\n",
    "    # Soma total das contagens no Corpus (T)\n",
    "    T = word_count_rdd.map(lambda x: x[1]).sum()\n",
    "\n",
    "    # Calcula log10(c/T) para cada palavra\n",
    "    return word_count_rdd.map(\n",
    "        lambda x: (x[0], math.log10(x[1] / T))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09116064-380c-43ed-91a3-736c80b47fb9",
   "metadata": {},
   "source": [
    "#### Tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47df9afe-f429-4951-954d-8ac0361efee6",
   "metadata": {},
   "source": [
    "Separe o RDD original em dois RDDs: o dos reviews positivos e o dos negativos. Em seguida, use as fun√ß√µes anteriores para construir RDDs que contem os pares (palavra, $\\log_{10}\\left(c \\, / \\, T\\right)$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987554e0-0a16-4827-9cc3-7c21063b1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que o RDD original se chama `rdd` no formato:\n",
    "# (sentiment:int, title:str, body:str)\n",
    "\n",
    "# 1Ô∏è‚É£ Separar por classe\n",
    "rdd_pos = rdd.filter(lambda x: x[0] == 1)   # positivos\n",
    "rdd_neg = rdd.filter(lambda x: x[0] == 0)   # negativos\n",
    "\n",
    "# 2Ô∏è‚É£ Gerar contagem das palavras por classe\n",
    "word_counts_pos = words_count(rdd_pos)\n",
    "word_counts_neg = words_count(rdd_neg)\n",
    "\n",
    "# 3Ô∏è‚É£ Converter para probabilidades logar√≠tmicas\n",
    "log_probs_pos = to_log_prob(word_counts_pos)\n",
    "log_probs_neg = to_log_prob(word_counts_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfe5957-73d2-45ad-9ad2-6e029668bacf",
   "metadata": {},
   "source": [
    "### Tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904cb0c8-2236-47aa-8ab0-3ad925bb24ed",
   "metadata": {},
   "source": [
    "Use o `.fullOuterJoin()` dos RDDs para construir um RDD unificado, no qual cada item √© da forma (palavra, log_prob_positivo, log_prob_negativo). \"Baixe\" esse resultado final usando `.collect()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b599156-e71d-46b4-9499-8d2dfe072512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Junta as probabilidades usando fullOuterJoin\n",
    "joined_rdd = log_probs_pos.fullOuterJoin(log_probs_neg)\n",
    "\n",
    "# Ajusta o formato para (palavra, log_prob_pos, log_prob_neg)\n",
    "# Substituindo None por 0.0 (para evitar erros futuros)\n",
    "model_rdd = joined_rdd.map(\n",
    "    lambda x: (\n",
    "        x[0],\n",
    "        x[1][0] if x[1][0] is not None else 0.0,  # log_prob_pos\n",
    "        x[1][1] if x[1][1] is not None else 0.0   # log_prob_neg\n",
    "    )\n",
    ")\n",
    "\n",
    "# Baixa para o driver (‚ö†Ô∏è pode ser grande!)\n",
    "modelo = model_rdd.collect()\n",
    "\n",
    "# Exibe os primeiros itens como exemplo\n",
    "print(modelo[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e90473-6725-4f30-9130-f5a0f370d968",
   "metadata": {},
   "source": [
    "#### Tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423d2117-397c-4a66-b63b-ca00036c1e2d",
   "metadata": {},
   "source": [
    "Para uma dada string, determine se ela √© um review positivo ou negativo usando os RDDs acima. Lembre-se de como funciona o classificador Naive-Bayes: http://stanford.edu/~jurafsky/slp3/slides/7_NB.pdf, consulte tambem suas notas de aula de Ci√™ncia dos Dados!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f68949-61c8-46b4-a39e-bcfb3872c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math\n",
    "\n",
    "# --- util: mesma tokeniza√ß√£o usada antes ---\n",
    "def _tokenize(text: str):\n",
    "    return re.findall(r\"[a-zA-Z]+\", text.lower())\n",
    "\n",
    "# --- preparar priors (contagem de documentos por classe) ---\n",
    "N_pos = rdd_pos.count()\n",
    "N_neg = rdd_neg.count()\n",
    "N_tot = N_pos + N_neg\n",
    "log_prior_pos = math.log10(N_pos / N_tot) if N_pos > 0 else float(\"-inf\")\n",
    "log_prior_neg = math.log10(N_neg / N_tot) if N_neg > 0 else float(\"-inf\")\n",
    "\n",
    "# --- totais por classe e tamanho do vocabul√°rio (para smoothing) ---\n",
    "T_pos = word_counts_pos.map(lambda x: x[1]).sum()\n",
    "T_neg = word_counts_neg.map(lambda x: x[1]).sum()\n",
    "V = (word_counts_pos.keys().union(word_counts_neg.keys())).distinct().count()\n",
    "\n",
    "# --- dicion√°rio/broadcast com (palavra -> (logp_pos, logp_neg)) ---\n",
    "# Se voc√™ j√° tem `modelo` (coletado), reaproveite; sen√£o, colete agora:\n",
    "try:\n",
    "    modelo  # s√≥ verifica se existe\n",
    "    _pairs = modelo\n",
    "except NameError:\n",
    "    _pairs = (log_probs_pos\n",
    "              .fullOuterJoin(log_probs_neg)\n",
    "              .map(lambda x: (x[0],\n",
    "                              x[1][0] if x[1][0] is not None else 0.0,\n",
    "                              x[1][1] if x[1][1] is not None else 0.0))\n",
    "              .collect())\n",
    "\n",
    "_model_dict = {w: (lp_pos, lp_neg) for (w, lp_pos, lp_neg) in _pairs}\n",
    "bc_model = sc.broadcast(_model_dict)\n",
    "\n",
    "def classify_review(text: str, alpha: float = 1.0):\n",
    "    \"\"\"\n",
    "    Classifica um texto como positivo (1) ou negativo (0) usando Naive Bayes (multinomial).\n",
    "    - Usa log-somas para estabilidade num√©rica.\n",
    "    - Aplica Laplace smoothing (alpha) para palavras fora do vocabul√°rio.\n",
    "    Retorna: dict com classe, scores, e probabilidades.\n",
    "    \"\"\"\n",
    "    tokens = _tokenize(text)\n",
    "\n",
    "    # backoff (palavra OOV) com smoothing multinomial:\n",
    "    # P(w|classe) = (alpha) / (T_classe + alpha*V)\n",
    "    # trabalhamos diretamente no log10:\n",
    "    if alpha > 0:\n",
    "        log_backoff_pos = math.log10(alpha / (T_pos + alpha * V))\n",
    "        log_backoff_neg = math.log10(alpha / (T_neg + alpha * V))\n",
    "    else:\n",
    "        # sem smoothing: ignorar OOV (contribui√ß√£o 0 no log-sum ‚Üí n√£o somar)\n",
    "        log_backoff_pos = None\n",
    "        log_backoff_neg = None\n",
    "\n",
    "    log_score_pos = log_prior_pos\n",
    "    log_score_neg = log_prior_neg\n",
    "    mdict = bc_model.value\n",
    "\n",
    "    for w in tokens:\n",
    "        vals = mdict.get(w)\n",
    "        if vals is not None:\n",
    "            lp_pos, lp_neg = vals\n",
    "            log_score_pos += lp_pos\n",
    "            log_score_neg += lp_neg\n",
    "        else:\n",
    "            if alpha > 0:\n",
    "                log_score_pos += log_backoff_pos\n",
    "                log_score_neg += log_backoff_neg\n",
    "            # se alpha == 0 e palavra n√£o existe, simplesmente n√£o somamos nada\n",
    "\n",
    "    # decis√£o\n",
    "    predicted = 1 if log_score_pos >= log_score_neg else 0\n",
    "\n",
    "    # probabilidades a partir dos log-scores (base 10):\n",
    "    # p_pos ‚àù 10^{log_score_pos}; p_neg ‚àù 10^{log_score_neg}\n",
    "    # normaliza√ß√£o est√°vel via diferen√ßa:\n",
    "    diff = log_score_neg - log_score_pos\n",
    "    # p_pos = 1 / (1 + 10^{diff})\n",
    "    p_pos = 1.0 / (1.0 + (10 ** diff))\n",
    "    p_neg = 1.0 - p_pos\n",
    "\n",
    "    return {\n",
    "        \"predicted\": predicted,          # 1 = positivo, 0 = negativo\n",
    "        \"log_score_pos\": log_score_pos,\n",
    "        \"log_score_neg\": log_score_neg,\n",
    "        \"p_pos\": p_pos,\n",
    "        \"p_neg\": p_neg,\n",
    "        \"tokens_used\": len(tokens)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab052fff-3752-4476-88f5-bc6b654c8e02",
   "metadata": {},
   "source": [
    "### Fase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7071fa13-c31b-434e-969f-538c0070fb34",
   "metadata": {},
   "source": [
    "Agora que temos um classificador Naive-Bayes, vamos explor√°-lo um pouco:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ed5be5-9e8d-4a7f-98bc-592cc7ecee74",
   "metadata": {},
   "source": [
    "### Tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb9bd58-1023-4cb7-861e-6cdbe5384356",
   "metadata": {},
   "source": [
    "Quais s√£o as 100 palavras que mais indicam negatividade, ou seja, onde a diferen√ßa entre a probabilidade da palavra no conjunto dos coment√°rios negativos e positivos √© m√°xima? E quais as 100 palavras de maior positividade? Mostre os resultados na forma de *word clouds*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c147d964-8720-43fa-a8e3-0610394a752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1Ô∏è‚É£ Unir probabilidades logaritmicas em um √∫nico RDD\n",
    "joined_rdd = log_probs_pos.fullOuterJoin(log_probs_neg)\n",
    "\n",
    "# 2Ô∏è‚É£ Calcular a diferen√ßa:\n",
    "# diff = log(P(w|neg)) - log(P(w|pos))\n",
    "# Quanto maior diff, mais negativa a palavra\n",
    "diff_rdd = joined_rdd.map(\n",
    "    lambda x: (\n",
    "        x[0],\n",
    "        (x[1][1] if x[1][1] is not None else 0.0)\n",
    "        - (x[1][0] if x[1][0] is not None else 0.0)\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3Ô∏è‚É£ Top-100 palavras mais negativas (maior diff)\n",
    "top_neg_100 = diff_rdd.takeOrdered(100, key=lambda x: -x[1])\n",
    "\n",
    "# 4Ô∏è‚É£ Top-100 palavras mais positivas (menor diff)\n",
    "top_pos_100 = diff_rdd.takeOrdered(100, key=lambda x: x[1])\n",
    "\n",
    "print(\"Exemplo negativas:\", top_neg_100[:10])\n",
    "print(\"Exemplo positivas:\", top_pos_100[:10])\n",
    "\n",
    "# ‚úÖ Converter para dicion√°rios de frequ√™ncias para visualiza√ß√£o em WordCloud\n",
    "# Quanto maior o valor ‚Üí maior a palavra na nuvem\n",
    "neg_dict = {word: float(diff) for word, diff in top_neg_100}\n",
    "pos_dict = {word: float(-diff) for word, diff in top_pos_100}  # invertendo sinal\n",
    "\n",
    "# 5Ô∏è‚É£ Word Clouds üìä‚ú®\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "wc_neg = WordCloud(width=800, height=600, background_color=\"white\")\n",
    "wc_neg.generate_from_frequencies(neg_dict)\n",
    "axes[0].imshow(wc_neg, interpolation=\"bilinear\")\n",
    "axes[0].set_title(\"Palavras mais Negativas\", fontsize=20)\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "wc_pos = WordCloud(width=800, height=600, background_color=\"white\")\n",
    "wc_pos.generate_from_frequencies(pos_dict)\n",
    "axes[1].imshow(wc_pos, interpolation=\"bilinear\")\n",
    "axes[1].set_title(\"Palavras mais Positivas\", fontsize=20)\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8854a0bf-1941-47eb-a1f5-6b3f4d34f857",
   "metadata": {},
   "source": [
    "### Tarefa desafio!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a98d11-16d6-4d97-b1ab-14db145e826e",
   "metadata": {},
   "source": [
    "Qual o desempenho do classificador (acur√°cia)? Para medir sua acur√°cia:\n",
    "\n",
    "- Separe os reviews em dois conjuntos: treinamente e teste\n",
    "- Repita o \"treinamento\" do classificador com o conjunto de treinamento\n",
    "- Para cada review do conjunto de teste, determine se √© positiva ou negativa de acordo com o classificador\n",
    "- Determine a acur√°cia\n",
    "\n",
    "Esta n√£o √© uma tarefa trivial. N√£o basta fazer um `for` para determinar a classe de cada review de teste: isso demoraria uma eternidade. Voc√™ tem que usar vari√°veis \"broadcast\" do Spark para enviar uma c√≥pia da tabela de frequencias para cada *core* do executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93decd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Ajustes / utilidades ===\n",
    "import re, math\n",
    "\n",
    "def _tokenize(text: str):\n",
    "    # Mesma tokeniza√ß√£o usada nas fases anteriores\n",
    "    return re.findall(r\"[a-zA-Z]+\", (text or \"\").lower())\n",
    "\n",
    "# === 1) Split: treino e teste ===\n",
    "# rdd: (label:int, title:str, body:str)\n",
    "rdd_train, rdd_test = rdd.randomSplit([0.8, 0.2], seed=42)\n",
    "rdd_train = rdd_train.cache()\n",
    "rdd_test  = rdd_test.cache()\n",
    "\n",
    "# === 2) \"Treinamento\" no conjunto de treino ===\n",
    "# Separar por classe (0 = neg, 1 = pos)\n",
    "rdd_train_pos = rdd_train.filter(lambda x: x[0] == 1).cache()\n",
    "rdd_train_neg = rdd_train.filter(lambda x: x[0] == 0).cache()\n",
    "\n",
    "# Priors (por documentos no treino)\n",
    "N_pos = rdd_train_pos.count()\n",
    "N_neg = rdd_train_neg.count()\n",
    "N_tot = N_pos + N_neg\n",
    "log_prior_pos = math.log10(N_pos / N_tot) if N_pos > 0 else float(\"-inf\")\n",
    "log_prior_neg = math.log10(N_neg / N_tot) if N_neg > 0 else float(\"-inf\")\n",
    "\n",
    "# Contagens de palavras por classe (treino)\n",
    "word_counts_pos = words_count(rdd_train_pos)  # (w, c_pos)\n",
    "word_counts_neg = words_count(rdd_train_neg)  # (w, c_neg)\n",
    "\n",
    "# Totais por classe (T_pos/T_neg) e vocabul√°rio |V| (treino)\n",
    "T_pos = word_counts_pos.map(lambda x: x[1]).sum()\n",
    "T_neg = word_counts_neg.map(lambda x: x[1]).sum()\n",
    "V = (word_counts_pos.keys().union(word_counts_neg.keys())).distinct().count()\n",
    "\n",
    "# Probabilidades log (sem smoothing aqui; smoothing entra na classifica√ß√£o para OOV)\n",
    "log_probs_pos = to_log_prob(word_counts_pos)  # (w, log10(c/T_pos))\n",
    "log_probs_neg = to_log_prob(word_counts_neg)  # (w, log10(c/T_neg))\n",
    "\n",
    "# Dicion√°rios para broadcast\n",
    "dict_log_pos = log_probs_pos.collectAsMap()   # palavra -> logP(w|pos)\n",
    "dict_log_neg = log_probs_neg.collectAsMap()   # palavra -> logP(w|neg)\n",
    "\n",
    "bc_log_pos = sc.broadcast(dict_log_pos)\n",
    "bc_log_neg = sc.broadcast(dict_log_neg)\n",
    "\n",
    "# Smoothing (Laplace) para palavras fora do vocabul√°rio do treino\n",
    "alpha = 1.0\n",
    "log_backoff_pos = math.log10(alpha / (T_pos + alpha * V)) if T_pos > 0 else float(\"-inf\")\n",
    "log_backoff_neg = math.log10(alpha / (T_neg + alpha * V)) if T_neg > 0 else float(\"-inf\")\n",
    "\n",
    "# === 3) Classificar o conjunto de teste de forma distribu√≠da (sem collect/for) ===\n",
    "def _classify_record(rec):\n",
    "    \"\"\"\n",
    "    rec: (label, title, body)\n",
    "    retorna: (pred, label)\n",
    "    \"\"\"\n",
    "    label, title, body = rec\n",
    "    tokens = _tokenize((title or \"\") + \" \" + (body or \"\"))\n",
    "\n",
    "    lp_pos = bc_log_pos.value\n",
    "    lp_neg = bc_log_neg.value\n",
    "\n",
    "    score_pos = log_prior_pos\n",
    "    score_neg = log_prior_neg\n",
    "\n",
    "    # Multinomial NB: soma log-prob por ocorr√™ncia (conta repeti√ß√µes)\n",
    "    for w in tokens:\n",
    "        score_pos += lp_pos.get(w, log_backoff_pos)\n",
    "        score_neg += lp_neg.get(w, log_backoff_neg)\n",
    "\n",
    "    pred = 1 if score_pos >= score_neg else 0\n",
    "    return (pred, label)\n",
    "\n",
    "pred_vs_true = rdd_test.map(_classify_record)\n",
    "\n",
    "# === 4) Acur√°cia ===\n",
    "n_total   = pred_vs_true.count()\n",
    "n_correct = pred_vs_true.filter(lambda x: x[0] == x[1]).count()\n",
    "accuracy  = n_correct / n_total if n_total > 0 else float(\"nan\")\n",
    "\n",
    "print(f\"Acur√°cia no conjunto de teste: {accuracy:.4f}  (acertos: {n_correct} / {n_total})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12a2c0d-7bfc-40bf-b717-1414c1df05ec",
   "metadata": {},
   "source": [
    "### Tarefa desafio!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af21c4e-5a5b-4127-80a0-d79e95f03b8f",
   "metadata": {},
   "source": [
    "Implemente Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61c989-ec58-4ebe-be19-595ad9e4887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def to_log_prob_smoothed(word_count_rdd, alpha, V):\n",
    "    \"\"\"\n",
    "    Recebe um RDD (palavra, contagem)\n",
    "    Retorna (palavra, log10((c+alpha)/(T + alpha*V)))\n",
    "    Onde V = tamanho do vocabul√°rio\n",
    "    \"\"\"\n",
    "    T = word_count_rdd.map(lambda x: x[1]).sum()\n",
    "\n",
    "    return word_count_rdd.map(\n",
    "        lambda x: (\n",
    "            x[0],\n",
    "            math.log10((x[1] + alpha) / (T + alpha * V))\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08805b7b-f8b5-4b85-ab53-3c0813f79c44",
   "metadata": {},
   "source": [
    "## Rubrica de avalia√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74059567-1f3d-414a-bbc8-f5a7ea144b76",
   "metadata": {},
   "source": [
    "- I: groselha, falha cr√≠tica, ou n√£o entregou nada\n",
    "- D: Fez uma tentativa honesta de fazer todos os itens da fase 1, mas tem erros\n",
    "- C: Fase 1 completa\n",
    "- B: Fase 2, faltando apenas um desafio\n",
    "- A: Fase 2 completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33106eb-7a38-4d89-8a23-c14fce370bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
