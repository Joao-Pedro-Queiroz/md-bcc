{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b48e863-8e93-45c0-938d-c9a4566b69b8",
   "metadata": {},
   "source": [
    "# Projeto Spark\n",
    "\n",
    "Entrega: 16 de novembro de 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4813f033-927b-46ca-8977-30e8b0de48c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introdução\n",
    "\n",
    "Neste projeto vamos construir um classificador Naive-Bayes para determinar o sentimento de um comentário."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73210022",
   "metadata": {},
   "source": [
    "## Grupos\n",
    "\n",
    "O projeto pode ser individual ou em duplas. Criem os grupos em https://classroom.github.com/a/YQj6i16S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7c97a3",
   "metadata": {},
   "source": [
    "## Instalando o ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fb2a89",
   "metadata": {},
   "source": [
    "O jeito mais simples de começar a trabalhar com Spark é instalar um container com tudo pronto! No site https://hub.docker.com/r/jupyter/pyspark-notebook vemos uma imagem Docker que já vem com `pyspark` e `jupyter lab`. Instale a imagem com o comando:\n",
    "\n",
    "```bash\n",
    "docker pull jupyter/pyspark-notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d77aef5",
   "metadata": {},
   "source": [
    "\n",
    "Vamos iniciar o ambiente de trabalho com o comando `docker run`. Para isso precisamos tomar alguns cuidados:\n",
    "\n",
    "1) Temos que mapear nosso diretorio local de trabalho para um diretório interno do container, de modo que alterações feitas dentro do container (nesta pasta escolhida) sejam gravadas no nosso diretorio local. No container temos um usuário padrão com *username* `jovyan`. No *homedir* desse usuario temos uma pasta vazia `work`, que vai servir como local de mapeamento do nosso diretorio local de trabalho. Podemos então fazer esse mapeamendo com a opção `-v` do comando `docker run` da seguinte forma:\n",
    "\n",
    "```bash\n",
    "-v <diretorio>:/home/jovyan/work\n",
    "```\n",
    "\n",
    "onde `<diretorio>` representa seu diretorio local de trabalho.\n",
    "\n",
    "2) Para acessar o `jupyter notebook` e o *dashboard* do Spark a partir do nosso *browser* favorito temos que abrir algumas portas do container com a opção `-p`. As portas são `8888` (para o próprio `jupyter notebook`) e `4040` (para o *dashboard* do Spark). Ou seja, adicionaremos às opções do `docker run`o seguinte:\n",
    "\n",
    "```bash\n",
    "-p 8888:8888 -p 4040:4040\n",
    "```\n",
    "\n",
    "Desta forma, ao acessar `localhost:8888` na nossa máquina, estaremos acessando o servidor Jupyter na porta 8888 interna do container.\n",
    "\n",
    "3) Vamos iniciar o container no modo interativo, e vamos especificar que o container deve ser encerrado ao fechar o servidor Jupyter. Faremos isso com as opções `-it` e `-rm`\n",
    "\n",
    "Antes de executar, garanta que as portas 4040 e 8888 estão livres (sem jupyter já executando) ou altere o comando. Ainda, esteja na pasta da aula ao executar, assim apenas ela será exposta ao container.\n",
    "\n",
    "Portanto, o comando completo que eu uso na minha máquina Linux para iniciar o container é:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5270810",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker run \\\n",
    "    -it \\\n",
    "    --rm \\\n",
    "    -p 8888:8888 \\\n",
    "    -p 4040:4040 \\\n",
    "    -v \"`pwd`\":/home/jovyan/work \\\n",
    "    jupyter/pyspark-notebook\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33432fba",
   "metadata": {},
   "source": [
    "Se estiver no Windows estes comandos, utilize:\n",
    "\n",
    "- No Powershell: `docker run -it --rm -p 8888:8888 -p 4040:4040 -v ${PWD}:/home/jovyan/work jupyter/pyspark-notebook`\n",
    "\n",
    "- No Prompt de comando: `docker run -it --rm -p 8888:8888 -p 4040:4040 -v %cd%:/home/jovyan/work jupyter/pyspark-notebook`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3090720d-0dec-48ff-a8da-921b62764c43",
   "metadata": {},
   "source": [
    "## Iniciando o Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603fa191-ca53-4035-9147-86f3cf27831a",
   "metadata": {},
   "source": [
    "Vamos iniciar o ambiente Spark. Para isso vamos:\n",
    "\n",
    "1) Criar um objeto de configuração do ambiente Spark. Nossa configuração será simples: vamos especificar que o nome da nossa aplicação Spark é \"Minha aplicação\", e que o *master node* é a máquina local, usando todos os *cores* disponíveis. Aplicações reais de Spark são configuradas de modo ligeiramente diferente: ao especificar o *master node* passamos uma URL real, com o endereço do nó gerente do *cluster* Spark.\n",
    "\n",
    "2) Vamos criar um objeto do tipo `SparkContext` com essa configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d1b7f8-ddc9-43b0-adbd-2b6e5aad182c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "conf = pyspark.SparkConf()\n",
    "conf.setAppName(\"Meu projeto Spark\")\n",
    "conf.setMaster(\"local[*]\")\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfcd1c3-3c9b-47c6-bf36-06c60b796991",
   "metadata": {},
   "source": [
    "O `SparkContext` é a nossa porta de entrada para o cluster Spark, ele será a raiz de todas as nossas operações com o Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5214f8ff-9df1-4817-9e08-c1755470f3b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://b2c10cc0900a:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Minha aplicação</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=Minha aplicação>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60acb677-070b-4191-bbad-ee16000ff380",
   "metadata": {},
   "source": [
    "O link acima provavelmente não funcionará porque ele se refere à porta 4040 interna do container (portanto a URL está com endereço interno). Porém fizemos o mapeamento da porta 4040 interna para a porta 4040 externa, logo você pode acessar o *dashboard* do Spark no endereço http://localhost:4040\n",
    "\n",
    "<center><img src=\"./spark_dashboard.png\" width=800/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44bd07e-7f64-4c0d-b522-faf5313b53cc",
   "metadata": {},
   "source": [
    "## Lendo os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c2f3af",
   "metadata": {},
   "source": [
    "Utilize os dados (`train.csv`) da aula 22. Caso queira fazer download novamente, utilize um dos links:\n",
    "\n",
    "- https://www.kaggle.com/datasets/kritanjalijain/amazon-reviews.\n",
    "- https://bigdata-22-2.s3.us-east-2.amazonaws.com/amazon_sentiment/train.csv.gz\n",
    "\n",
    "Vamos começar lendo o arquivo de reviews e gravando o resultado em formato pickle, mais amigável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7fda56-bf06-4309-a265-26e553e20b94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_line(line):\n",
    "    parts = line[1:-1].split('\",\"')\n",
    "    sentiment = int(parts[0])\n",
    "    title = parts[1].replace('\"\"', '\"')\n",
    "    body = parts[2].replace('\"\"', '\"')\n",
    "    return (sentiment, title, body)\n",
    "\n",
    "rdd = sc.textFile(\"train.csv\").map(parse_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "900ea746-984c-405b-a449-d6cf8885525e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e83f38e5-3d7b-4261-8ab3-caadb39d6076",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2,\n",
       "  'Stuning even for the non-gamer',\n",
       "  'This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c7933-ad3f-4a17-bf89-8e1360ddc4ab",
   "metadata": {},
   "source": [
    "Agora vamos gravar no formato pickle, para facilitar os trabalhos futuros. Após gravar o arquivo, não mais rode as células desta primeira etapa!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39938d62-bc17-4243-a9e8-3fed9c8d2bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.saveAsPickleFile(\"reviews.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f5b5b-f0ac-4385-866b-8d8d8ecbdf9f",
   "metadata": {},
   "source": [
    "## Um classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ef2e6-ac48-46ad-b538-920c17aff6dc",
   "metadata": {},
   "source": [
    "Vamos ler o arquivo pickle gravado anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9107ce80-0447-41d7-8f83-d96f0680d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.pickleFile('reviews.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae84b476-b262-496f-93b0-19386fa9f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607f7afa-43e7-4b82-bffc-7c1cca0536ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9751aa-df6d-4e3e-a8c5-039133cefe28",
   "metadata": {},
   "source": [
    "Agora, complete as tarefas em sequencia para construir o classificador Naive-Bayes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bac409-7181-49c4-b555-73d3e9ff71f2",
   "metadata": {},
   "source": [
    "### Fase 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef78654e-d064-41b4-9be8-306a57c425f4",
   "metadata": {},
   "source": [
    "#### Tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d82f8-520e-49de-8397-5277d5bd072e",
   "metadata": {},
   "source": [
    "Construa uma função que recebe um RDD no formato do RDD original e retorna um RDD no qual cada item é um par (palavra, contagem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb48e97-e57d-4b6a-9b27-b52cd9c3d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def words_count(rdd):\n",
    "    \"\"\"\n",
    "    Recebe um RDD no formato (sentiment, title, body)\n",
    "    Retorna um RDD (palavra, contagem)\n",
    "    \"\"\"\n",
    "    \n",
    "    def tokenize(text):\n",
    "        # transforma em minúsculas e remove caracteres não alfabéticos\n",
    "        return re.findall(r\"[a-zA-Z]+\", text.lower())\n",
    "    \n",
    "    return (rdd\n",
    "        # extrair apenas o texto: título + corpo\n",
    "        .flatMap(lambda x: tokenize(x[1] + \" \" + x[2]))\n",
    "        # criar pares (palavra, 1)\n",
    "        .map(lambda word: (word, 1))\n",
    "        # somar as ocorrências\n",
    "        .reduceByKey(lambda a, b: a + b)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d888c4-bef5-4d1c-a901-e8dc5029f1b0",
   "metadata": {},
   "source": [
    "#### Tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ec5621-6c06-4dce-b351-e887d6aa8be4",
   "metadata": {},
   "source": [
    "Construa uma função que recebe o RDD (palavra, contagem) construido anteriormente e retorna um RDD no qual cada item é um par (palavra, $\\log_{10}\\left(c \\, / \\, T\\right)$), onde $c$ é a contagem daquela palavra e $T$ é a soma das contagens de palavra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca379b49-a447-4ecf-9946-6c408e2adc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def to_log_prob(word_count_rdd):\n",
    "    \"\"\"\n",
    "    Recebe um RDD (palavra, contagem)\n",
    "    Retorna um RDD (palavra, log10(c/T))\n",
    "    onde T é a soma das contagens de todas as palavras.\n",
    "    \"\"\"\n",
    "    # Soma total das contagens no Corpus (T)\n",
    "    T = word_count_rdd.map(lambda x: x[1]).sum()\n",
    "\n",
    "    # Calcula log10(c/T) para cada palavra\n",
    "    return word_count_rdd.map(\n",
    "        lambda x: (x[0], math.log10(x[1] / T))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09116064-380c-43ed-91a3-736c80b47fb9",
   "metadata": {},
   "source": [
    "#### Tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47df9afe-f429-4951-954d-8ac0361efee6",
   "metadata": {},
   "source": [
    "Separe o RDD original em dois RDDs: o dos reviews positivos e o dos negativos. Em seguida, use as funções anteriores para construir RDDs que contem os pares (palavra, $\\log_{10}\\left(c \\, / \\, T\\right)$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987554e0-0a16-4827-9cc3-7c21063b1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que o RDD original se chama `rdd` no formato:\n",
    "# (sentiment:int, title:str, body:str)\n",
    "\n",
    "# 1️⃣ Separar por classe\n",
    "rdd_pos = rdd.filter(lambda x: x[0] == 1)   # positivos\n",
    "rdd_neg = rdd.filter(lambda x: x[0] == 0)   # negativos\n",
    "\n",
    "# 2️⃣ Gerar contagem das palavras por classe\n",
    "word_counts_pos = words_count(rdd_pos)\n",
    "word_counts_neg = words_count(rdd_neg)\n",
    "\n",
    "# 3️⃣ Converter para probabilidades logarítmicas\n",
    "log_probs_pos = to_log_prob(word_counts_pos)\n",
    "log_probs_neg = to_log_prob(word_counts_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfe5957-73d2-45ad-9ad2-6e029668bacf",
   "metadata": {},
   "source": [
    "### Tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904cb0c8-2236-47aa-8ab0-3ad925bb24ed",
   "metadata": {},
   "source": [
    "Use o `.fullOuterJoin()` dos RDDs para construir um RDD unificado, no qual cada item é da forma (palavra, log_prob_positivo, log_prob_negativo). \"Baixe\" esse resultado final usando `.collect()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b599156-e71d-46b4-9499-8d2dfe072512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Junta as probabilidades usando fullOuterJoin\n",
    "joined_rdd = log_probs_pos.fullOuterJoin(log_probs_neg)\n",
    "\n",
    "# Ajusta o formato para (palavra, log_prob_pos, log_prob_neg)\n",
    "# Substituindo None por 0.0 (para evitar erros futuros)\n",
    "model_rdd = joined_rdd.map(\n",
    "    lambda x: (\n",
    "        x[0],\n",
    "        x[1][0] if x[1][0] is not None else 0.0,  # log_prob_pos\n",
    "        x[1][1] if x[1][1] is not None else 0.0   # log_prob_neg\n",
    "    )\n",
    ")\n",
    "\n",
    "# Baixa para o driver (⚠️ pode ser grande!)\n",
    "modelo = model_rdd.collect()\n",
    "\n",
    "# Exibe os primeiros itens como exemplo\n",
    "print(modelo[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e90473-6725-4f30-9130-f5a0f370d968",
   "metadata": {},
   "source": [
    "#### Tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423d2117-397c-4a66-b63b-ca00036c1e2d",
   "metadata": {},
   "source": [
    "Para uma dada string, determine se ela é um review positivo ou negativo usando os RDDs acima. Lembre-se de como funciona o classificador Naive-Bayes: http://stanford.edu/~jurafsky/slp3/slides/7_NB.pdf, consulte tambem suas notas de aula de Ciência dos Dados!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f68949-61c8-46b4-a39e-bcfb3872c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math\n",
    "\n",
    "# --- util: mesma tokenização usada antes ---\n",
    "def _tokenize(text: str):\n",
    "    return re.findall(r\"[a-zA-Z]+\", text.lower())\n",
    "\n",
    "# --- preparar priors (contagem de documentos por classe) ---\n",
    "N_pos = rdd_pos.count()\n",
    "N_neg = rdd_neg.count()\n",
    "N_tot = N_pos + N_neg\n",
    "log_prior_pos = math.log10(N_pos / N_tot) if N_pos > 0 else float(\"-inf\")\n",
    "log_prior_neg = math.log10(N_neg / N_tot) if N_neg > 0 else float(\"-inf\")\n",
    "\n",
    "# --- totais por classe e tamanho do vocabulário (para smoothing) ---\n",
    "T_pos = word_counts_pos.map(lambda x: x[1]).sum()\n",
    "T_neg = word_counts_neg.map(lambda x: x[1]).sum()\n",
    "V = (word_counts_pos.keys().union(word_counts_neg.keys())).distinct().count()\n",
    "\n",
    "# --- dicionário/broadcast com (palavra -> (logp_pos, logp_neg)) ---\n",
    "# Se você já tem `modelo` (coletado), reaproveite; senão, colete agora:\n",
    "try:\n",
    "    modelo  # só verifica se existe\n",
    "    _pairs = modelo\n",
    "except NameError:\n",
    "    _pairs = (log_probs_pos\n",
    "              .fullOuterJoin(log_probs_neg)\n",
    "              .map(lambda x: (x[0],\n",
    "                              x[1][0] if x[1][0] is not None else 0.0,\n",
    "                              x[1][1] if x[1][1] is not None else 0.0))\n",
    "              .collect())\n",
    "\n",
    "_model_dict = {w: (lp_pos, lp_neg) for (w, lp_pos, lp_neg) in _pairs}\n",
    "bc_model = sc.broadcast(_model_dict)\n",
    "\n",
    "def classify_review(text: str, alpha: float = 1.0):\n",
    "    \"\"\"\n",
    "    Classifica um texto como positivo (1) ou negativo (0) usando Naive Bayes (multinomial).\n",
    "    - Usa log-somas para estabilidade numérica.\n",
    "    - Aplica Laplace smoothing (alpha) para palavras fora do vocabulário.\n",
    "    Retorna: dict com classe, scores, e probabilidades.\n",
    "    \"\"\"\n",
    "    tokens = _tokenize(text)\n",
    "\n",
    "    # backoff (palavra OOV) com smoothing multinomial:\n",
    "    # P(w|classe) = (alpha) / (T_classe + alpha*V)\n",
    "    # trabalhamos diretamente no log10:\n",
    "    if alpha > 0:\n",
    "        log_backoff_pos = math.log10(alpha / (T_pos + alpha * V))\n",
    "        log_backoff_neg = math.log10(alpha / (T_neg + alpha * V))\n",
    "    else:\n",
    "        # sem smoothing: ignorar OOV (contribuição 0 no log-sum → não somar)\n",
    "        log_backoff_pos = None\n",
    "        log_backoff_neg = None\n",
    "\n",
    "    log_score_pos = log_prior_pos\n",
    "    log_score_neg = log_prior_neg\n",
    "    mdict = bc_model.value\n",
    "\n",
    "    for w in tokens:\n",
    "        vals = mdict.get(w)\n",
    "        if vals is not None:\n",
    "            lp_pos, lp_neg = vals\n",
    "            log_score_pos += lp_pos\n",
    "            log_score_neg += lp_neg\n",
    "        else:\n",
    "            if alpha > 0:\n",
    "                log_score_pos += log_backoff_pos\n",
    "                log_score_neg += log_backoff_neg\n",
    "            # se alpha == 0 e palavra não existe, simplesmente não somamos nada\n",
    "\n",
    "    # decisão\n",
    "    predicted = 1 if log_score_pos >= log_score_neg else 0\n",
    "\n",
    "    # probabilidades a partir dos log-scores (base 10):\n",
    "    # p_pos ∝ 10^{log_score_pos}; p_neg ∝ 10^{log_score_neg}\n",
    "    # normalização estável via diferença:\n",
    "    diff = log_score_neg - log_score_pos\n",
    "    # p_pos = 1 / (1 + 10^{diff})\n",
    "    p_pos = 1.0 / (1.0 + (10 ** diff))\n",
    "    p_neg = 1.0 - p_pos\n",
    "\n",
    "    return {\n",
    "        \"predicted\": predicted,          # 1 = positivo, 0 = negativo\n",
    "        \"log_score_pos\": log_score_pos,\n",
    "        \"log_score_neg\": log_score_neg,\n",
    "        \"p_pos\": p_pos,\n",
    "        \"p_neg\": p_neg,\n",
    "        \"tokens_used\": len(tokens)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab052fff-3752-4476-88f5-bc6b654c8e02",
   "metadata": {},
   "source": [
    "### Fase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7071fa13-c31b-434e-969f-538c0070fb34",
   "metadata": {},
   "source": [
    "Agora que temos um classificador Naive-Bayes, vamos explorá-lo um pouco:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ed5be5-9e8d-4a7f-98bc-592cc7ecee74",
   "metadata": {},
   "source": [
    "### Tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb9bd58-1023-4cb7-861e-6cdbe5384356",
   "metadata": {},
   "source": [
    "Quais são as 100 palavras que mais indicam negatividade, ou seja, onde a diferença entre a probabilidade da palavra no conjunto dos comentários negativos e positivos é máxima? E quais as 100 palavras de maior positividade? Mostre os resultados na forma de *word clouds*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c147d964-8720-43fa-a8e3-0610394a752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1️⃣ Unir probabilidades logaritmicas em um único RDD\n",
    "joined_rdd = log_probs_pos.fullOuterJoin(log_probs_neg)\n",
    "\n",
    "# 2️⃣ Calcular a diferença:\n",
    "# diff = log(P(w|neg)) - log(P(w|pos))\n",
    "# Quanto maior diff, mais negativa a palavra\n",
    "diff_rdd = joined_rdd.map(\n",
    "    lambda x: (\n",
    "        x[0],\n",
    "        (x[1][1] if x[1][1] is not None else 0.0)\n",
    "        - (x[1][0] if x[1][0] is not None else 0.0)\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3️⃣ Top-100 palavras mais negativas (maior diff)\n",
    "top_neg_100 = diff_rdd.takeOrdered(100, key=lambda x: -x[1])\n",
    "\n",
    "# 4️⃣ Top-100 palavras mais positivas (menor diff)\n",
    "top_pos_100 = diff_rdd.takeOrdered(100, key=lambda x: x[1])\n",
    "\n",
    "print(\"Exemplo negativas:\", top_neg_100[:10])\n",
    "print(\"Exemplo positivas:\", top_pos_100[:10])\n",
    "\n",
    "# ✅ Converter para dicionários de frequências para visualização em WordCloud\n",
    "# Quanto maior o valor → maior a palavra na nuvem\n",
    "neg_dict = {word: float(diff) for word, diff in top_neg_100}\n",
    "pos_dict = {word: float(-diff) for word, diff in top_pos_100}  # invertendo sinal\n",
    "\n",
    "# 5️⃣ Word Clouds 📊✨\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "wc_neg = WordCloud(width=800, height=600, background_color=\"white\")\n",
    "wc_neg.generate_from_frequencies(neg_dict)\n",
    "axes[0].imshow(wc_neg, interpolation=\"bilinear\")\n",
    "axes[0].set_title(\"Palavras mais Negativas\", fontsize=20)\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "wc_pos = WordCloud(width=800, height=600, background_color=\"white\")\n",
    "wc_pos.generate_from_frequencies(pos_dict)\n",
    "axes[1].imshow(wc_pos, interpolation=\"bilinear\")\n",
    "axes[1].set_title(\"Palavras mais Positivas\", fontsize=20)\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8854a0bf-1941-47eb-a1f5-6b3f4d34f857",
   "metadata": {},
   "source": [
    "### Tarefa desafio!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a98d11-16d6-4d97-b1ab-14db145e826e",
   "metadata": {},
   "source": [
    "Qual o desempenho do classificador (acurácia)? Para medir sua acurácia:\n",
    "\n",
    "- Separe os reviews em dois conjuntos: treinamente e teste\n",
    "- Repita o \"treinamento\" do classificador com o conjunto de treinamento\n",
    "- Para cada review do conjunto de teste, determine se é positiva ou negativa de acordo com o classificador\n",
    "- Determine a acurácia\n",
    "\n",
    "Esta não é uma tarefa trivial. Não basta fazer um `for` para determinar a classe de cada review de teste: isso demoraria uma eternidade. Você tem que usar variáveis \"broadcast\" do Spark para enviar uma cópia da tabela de frequencias para cada *core* do executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93decd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Ajustes / utilidades ===\n",
    "import re, math\n",
    "\n",
    "def _tokenize(text: str):\n",
    "    # Mesma tokenização usada nas fases anteriores\n",
    "    return re.findall(r\"[a-zA-Z]+\", (text or \"\").lower())\n",
    "\n",
    "# === 1) Split: treino e teste ===\n",
    "# rdd: (label:int, title:str, body:str)\n",
    "rdd_train, rdd_test = rdd.randomSplit([0.8, 0.2], seed=42)\n",
    "rdd_train = rdd_train.cache()\n",
    "rdd_test  = rdd_test.cache()\n",
    "\n",
    "# === 2) \"Treinamento\" no conjunto de treino ===\n",
    "# Separar por classe (0 = neg, 1 = pos)\n",
    "rdd_train_pos = rdd_train.filter(lambda x: x[0] == 1).cache()\n",
    "rdd_train_neg = rdd_train.filter(lambda x: x[0] == 0).cache()\n",
    "\n",
    "# Priors (por documentos no treino)\n",
    "N_pos = rdd_train_pos.count()\n",
    "N_neg = rdd_train_neg.count()\n",
    "N_tot = N_pos + N_neg\n",
    "log_prior_pos = math.log10(N_pos / N_tot) if N_pos > 0 else float(\"-inf\")\n",
    "log_prior_neg = math.log10(N_neg / N_tot) if N_neg > 0 else float(\"-inf\")\n",
    "\n",
    "# Contagens de palavras por classe (treino)\n",
    "word_counts_pos = words_count(rdd_train_pos)  # (w, c_pos)\n",
    "word_counts_neg = words_count(rdd_train_neg)  # (w, c_neg)\n",
    "\n",
    "# Totais por classe (T_pos/T_neg) e vocabulário |V| (treino)\n",
    "T_pos = word_counts_pos.map(lambda x: x[1]).sum()\n",
    "T_neg = word_counts_neg.map(lambda x: x[1]).sum()\n",
    "V = (word_counts_pos.keys().union(word_counts_neg.keys())).distinct().count()\n",
    "\n",
    "# Probabilidades log (sem smoothing aqui; smoothing entra na classificação para OOV)\n",
    "log_probs_pos = to_log_prob(word_counts_pos)  # (w, log10(c/T_pos))\n",
    "log_probs_neg = to_log_prob(word_counts_neg)  # (w, log10(c/T_neg))\n",
    "\n",
    "# Dicionários para broadcast\n",
    "dict_log_pos = log_probs_pos.collectAsMap()   # palavra -> logP(w|pos)\n",
    "dict_log_neg = log_probs_neg.collectAsMap()   # palavra -> logP(w|neg)\n",
    "\n",
    "bc_log_pos = sc.broadcast(dict_log_pos)\n",
    "bc_log_neg = sc.broadcast(dict_log_neg)\n",
    "\n",
    "# Smoothing (Laplace) para palavras fora do vocabulário do treino\n",
    "alpha = 1.0\n",
    "log_backoff_pos = math.log10(alpha / (T_pos + alpha * V)) if T_pos > 0 else float(\"-inf\")\n",
    "log_backoff_neg = math.log10(alpha / (T_neg + alpha * V)) if T_neg > 0 else float(\"-inf\")\n",
    "\n",
    "# === 3) Classificar o conjunto de teste de forma distribuída (sem collect/for) ===\n",
    "def _classify_record(rec):\n",
    "    \"\"\"\n",
    "    rec: (label, title, body)\n",
    "    retorna: (pred, label)\n",
    "    \"\"\"\n",
    "    label, title, body = rec\n",
    "    tokens = _tokenize((title or \"\") + \" \" + (body or \"\"))\n",
    "\n",
    "    lp_pos = bc_log_pos.value\n",
    "    lp_neg = bc_log_neg.value\n",
    "\n",
    "    score_pos = log_prior_pos\n",
    "    score_neg = log_prior_neg\n",
    "\n",
    "    # Multinomial NB: soma log-prob por ocorrência (conta repetições)\n",
    "    for w in tokens:\n",
    "        score_pos += lp_pos.get(w, log_backoff_pos)\n",
    "        score_neg += lp_neg.get(w, log_backoff_neg)\n",
    "\n",
    "    pred = 1 if score_pos >= score_neg else 0\n",
    "    return (pred, label)\n",
    "\n",
    "pred_vs_true = rdd_test.map(_classify_record)\n",
    "\n",
    "# === 4) Acurácia ===\n",
    "n_total   = pred_vs_true.count()\n",
    "n_correct = pred_vs_true.filter(lambda x: x[0] == x[1]).count()\n",
    "accuracy  = n_correct / n_total if n_total > 0 else float(\"nan\")\n",
    "\n",
    "print(f\"Acurácia no conjunto de teste: {accuracy:.4f}  (acertos: {n_correct} / {n_total})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12a2c0d-7bfc-40bf-b717-1414c1df05ec",
   "metadata": {},
   "source": [
    "### Tarefa desafio!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af21c4e-5a5b-4127-80a0-d79e95f03b8f",
   "metadata": {},
   "source": [
    "Implemente Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61c989-ec58-4ebe-be19-595ad9e4887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def to_log_prob_smoothed(word_count_rdd, alpha, V):\n",
    "    \"\"\"\n",
    "    Recebe um RDD (palavra, contagem)\n",
    "    Retorna (palavra, log10((c+alpha)/(T + alpha*V)))\n",
    "    Onde V = tamanho do vocabulário\n",
    "    \"\"\"\n",
    "    T = word_count_rdd.map(lambda x: x[1]).sum()\n",
    "\n",
    "    return word_count_rdd.map(\n",
    "        lambda x: (\n",
    "            x[0],\n",
    "            math.log10((x[1] + alpha) / (T + alpha * V))\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08805b7b-f8b5-4b85-ab53-3c0813f79c44",
   "metadata": {},
   "source": [
    "## Rubrica de avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74059567-1f3d-414a-bbc8-f5a7ea144b76",
   "metadata": {},
   "source": [
    "- I: groselha, falha crítica, ou não entregou nada\n",
    "- D: Fez uma tentativa honesta de fazer todos os itens da fase 1, mas tem erros\n",
    "- C: Fase 1 completa\n",
    "- B: Fase 2, faltando apenas um desafio\n",
    "- A: Fase 2 completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33106eb-7a38-4d89-8a23-c14fce370bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
